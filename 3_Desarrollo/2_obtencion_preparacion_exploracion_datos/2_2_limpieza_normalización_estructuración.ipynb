{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa4bfae",
   "metadata": {},
   "source": [
    "# 2_1_Limpieza, Normalización y estructuración de series temporales\n",
    "# Preprocesamiento de Datos del Índice E-mini Nasdaq 100 (MNQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5888009",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilidades generales\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Manejo y procesamiento de datos\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Calendario de mercados\n",
    "import pandas_market_calendars as mcal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ae912",
   "metadata": {},
   "source": [
    "## 2. Contexto y fuente de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4589d",
   "metadata": {},
   "source": [
    "Los datos corresponden al contrato MNQ (Micro E-mini Nasdaq 100) descargados desde NinjaTrader con frecuencia de un minuto (formato OHLCV).\n",
    "\n",
    "- Open: precio de apertura\n",
    "- High: precio máximo\n",
    "- Low: precio mínimo\n",
    "- Close: precio de cierre\n",
    "- Volume: volumen negociado\n",
    "\n",
    "Los datos están en la zona horaria UTC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab5ec9",
   "metadata": {},
   "source": [
    "## 3. Generación de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8122f5c",
   "metadata": {},
   "source": [
    "Dado que los contratos se encuentran almacenados en archivos .txt dentro de la carpeta historicos_mnq, es necesario unificarlos en un único dataset consolidado.\n",
    "\n",
    "La siguiente función se encarga de leer los archivos .txt, asignar nombres a las columnas correspondientes y establecer la columna datetime como índice temporal del dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3ef377f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_df ():\n",
    "\n",
    "    # Ruta a los archivos .txt\n",
    "    ruta_historicos = './historicos_mnq/*.txt'  # Reemplace con su ruta local\n",
    "\n",
    "    # Lista para almacenar DataFrames individuales\n",
    "    df_mnq = []\n",
    "    \n",
    "    # Leer todos los archivos .txt\n",
    "    for archivo in glob.glob(ruta_historicos):\n",
    "        df = pd.read_csv(\n",
    "            archivo,\n",
    "            sep=';',\n",
    "            header=None,\n",
    "            names=['datetime', 'open', 'high', 'low', 'close', 'volume'],\n",
    "            dtype={'open': float, 'high': float, 'low': float, 'close': float, 'volume': int}\n",
    "        )\n",
    "\n",
    "        # Convertir columna 'datetime' al formato datetime real\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'], format='%Y%m%d %H%M%S')\n",
    "\n",
    "        # Establecer como índice\n",
    "        df.set_index('datetime', inplace=True)\n",
    "\n",
    "        df_mnq.append(df)\n",
    "\n",
    "    # Unir todos los DataFrames\n",
    "    df_mnq_raw = pd.concat(df_mnq)\n",
    "    # Ordenar por fecha si es necesario\n",
    "    df_mnq_raw.sort_index(inplace=True)\n",
    "    \n",
    "    return df_mnq_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ebcdd",
   "metadata": {},
   "source": [
    "El siguiente bloque de código verifica si el dataset consolidado ya ha sido generado previamente.\n",
    "\n",
    "En particular, comprueba la existencia del archivo mnq_raw_data.parquet.\n",
    "\n",
    "- Si el archivo está presente, se carga directamente en la variable df_mnq.\n",
    "\n",
    "- En caso contrario, se invoca la función generate_dataset() para generar el dataset a partir de los archivos originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ac213cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_o_generar_df():\n",
    "    \n",
    "    archivo = 'mnq_raw_data.parquet'\n",
    "\n",
    "    if os.path.exists(archivo):\n",
    "        print(\"Archivo encontrado. Cargando dataset desde disco...\")\n",
    "        df_mnq_raw = pd.read_parquet(archivo)\n",
    "        \n",
    "    else:\n",
    "        print(\"Archivo no encontrado. Generando dataset desde carpeta de historicos_mnq..\")\n",
    "        df_mnq_raw = generar_df()\n",
    "        df_mnq_raw.to_parquet(archivo, index=True)\n",
    "        print(\"El dataset df_mnq_raw ha sido creado...\")\n",
    "\n",
    "    return df_mnq_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c96c833f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo no encontrado. Generando dataset desde carpeta de historicos_mnq..\n",
      "El dataset df_mnq_raw ha sido creado...\n"
     ]
    }
   ],
   "source": [
    "df_mnq_raw = cargar_o_generar_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504382cf",
   "metadata": {},
   "source": [
    "## 4. Filtrado de días no hábiles y horario bursátil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23cdad4",
   "metadata": {},
   "source": [
    "### 4.1. Filtrado de fines de semana y feriados bursátiles estadounidenses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d44470",
   "metadata": {},
   "source": [
    "Es necesario filtrar del conjunto de datos aquellas filas correspondientes a sábados, domingos y feriados bursátiles. Para ello, se utilizará la librería pandas_market_calendars, que permite identificar los días hábiles de operación según el calendario oficial del NASDAQ.\n",
    "\n",
    "La función implementada filtra un DataFrame con índice de tipo DatetimeIndex, conservando únicamente aquellas filas cuya fecha coincida con un día hábil del mercado. La marca temporal completa (fecha y hora) se mantiene sin modificaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a7aa8f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_dias_habiles_nasdaq(df):\n",
    "    # Crear el calendario del mercado NASDAQ\n",
    "    nasdaq = mcal.get_calendar('NASDAQ')\n",
    "\n",
    "    # Obtener el rango de fechas del índice del DataFrame\n",
    "    start_date = df.index.min().date()\n",
    "    end_date = df.index.max().date()\n",
    "\n",
    "    # Obtener el cronograma de días hábiles del mercado\n",
    "    valid_dates = nasdaq.schedule(start_date=start_date, end_date=end_date).index.date\n",
    "\n",
    "    # Filtrar el DataFrame verificando si la fecha de cada marca temporal está en los días válidos\n",
    "    df_filtrado = df[df.index.normalize().isin(valid_dates)]\n",
    "\n",
    "    return df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9b91f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnq = filtrar_dias_habiles_nasdaq (df_mnq_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3030c8ac",
   "metadata": {},
   "source": [
    "### 4.2. Filtrado de horario de operación de mercado de New York (09:30 a 16:00) con pre mercado, desde las 08:30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a687c",
   "metadata": {},
   "source": [
    "Dado que los timestamps del índice (DatetimeIndex) provienen de archivos .txt sin información de zona horaria, es necesario indicar explícitamente a pandas que dichos valores están en formato UTC.\n",
    "\n",
    "Una vez establecido el timezone, se procede a convertir los timestamps desde UTC a la hora local del mercado estadounidense (zona US/Eastern), correspondiente a los horarios de operación del NASDAQ/NYSE. Esta conversión se realiza teniendo en cuenta automáticamente los ajustes por horario de verano o invierno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "73820485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurar_zona_horaria(df, from_tz='UTC', to_tz='America/New_York'):\n",
    "    \"\"\"\n",
    "    Asegura que el índice del DataFrame tenga zona horaria 'from_tz'\n",
    "    y lo convierte a la zona horaria 'to_tz'.\n",
    "    \"\"\"\n",
    "    if df.index.tz is None:\n",
    "        # Localiza en from_tz si no tiene zona horaria\n",
    "        df.index = df.index.tz_localize(from_tz)\n",
    "    # Convierte a la zona horaria deseada\n",
    "    df.index = df.index.tz_convert(to_tz)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3598a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnq = configurar_zona_horaria(df_mnq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb43243",
   "metadata": {},
   "source": [
    "La siguiente función selecciona únicamente las muestras que se encuentran dentro del horario regular de operación bursátil del NASDAQ.\n",
    "\n",
    "Filtra un DataFrame cuyo índice es de tipo DatetimeIndex, conservando solo aquellas filas cuya marca temporal se encuentre entre las 09:30 y 16:00 horas (US/Eastern), correspondientes al horario de negociación estándar en días hábiles de mercado.\n",
    "\n",
    "Particularmente, decido agregar una hora de pre mercado, desde las 08:30AM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a07ebb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_horas_habiles_nasdaq(df):\n",
    "    \n",
    "    # Filtrar solo las filas dentro de las horas de mercado (de 8:30 AM a 4:00 PM)\n",
    "    df_filtered = df.between_time('08:30:00', '16:00:00')\n",
    "    \n",
    "    # Retornar el DataFrame filtrado\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1514117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnq = filtrar_horas_habiles_nasdaq(df_mnq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71ac27",
   "metadata": {},
   "source": [
    "## 5. Análisis de registros diarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed73d4",
   "metadata": {},
   "source": [
    "Es necesario verificar que todos los días del conjunto de datos contengan la misma cantidad de registros y que estos sean consecutivos, es decir, que no falte ningún minuto dentro de cada jornada.\n",
    "\n",
    "La función analizar_registros_por_dia permite realizar este control sobre un DataFrame con índice de tipo datetime. La función contabiliza la cantidad de registros por día e imprime una tabla resumen que indica cuántos días presentan una determinada cantidad de registros. Esto resulta útil para identificar inconsistencias, como días incompletos o interrupciones en la frecuencia temporal esperada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6b03a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_registros_por_dia(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Analiza la cantidad de registros por día en un DataFrame con índice datetime.\n",
    "\n",
    "    Imprime:\n",
    "    - Distribución de la cantidad de registros por día.\n",
    "    - Porcentaje de días con menos registros que el valor más frecuente.\n",
    "\n",
    "    Retorna:\n",
    "    - Serie con el conteo de registros por cada día.\n",
    "    \"\"\"\n",
    "    # Contar la cantidad de registros por día\n",
    "    conteo_diario = df.groupby(df.index.date).size()\n",
    "\n",
    "    # Calcular la distribución de registros por día\n",
    "    distribucion = conteo_diario.value_counts().sort_index(ascending=False)\n",
    "    tabla = [[registros, cantidad_dias] for registros, cantidad_dias in distribucion.items()]\n",
    "\n",
    "    print(\"Distribución de cantidad de registros por día:\\n\")\n",
    "    print(tabulate(tabla, headers=[\"Registros por día\", \"Cantidad de días\"], tablefmt=\"grid\"))\n",
    "\n",
    "    # Determinar el valor más frecuente de registros por día\n",
    "    registros_dia_completo = conteo_diario.mode().iloc[0]\n",
    "    print(f\"\\nCantidad de registros en un día completo: {registros_dia_completo}\")\n",
    "\n",
    "    # Calcular el porcentaje de días incompletos\n",
    "    total_dias = len(conteo_diario)\n",
    "    dias_con_menos = (conteo_diario < registros_dia_completo).sum()\n",
    "    porcentaje = (dias_con_menos / total_dias) * 100\n",
    "\n",
    "    print(f\"Días con menos de {registros_dia_completo} registros: {dias_con_menos} de {total_dias} ({porcentaje:.2f}%)\")\n",
    "\n",
    "    return conteo_diario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "15b8e1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de cantidad de registros por día:\n",
      "\n",
      "+---------------------+--------------------+\n",
      "|   Registros por día |   Cantidad de días |\n",
      "+=====================+====================+\n",
      "|                 451 |               1201 |\n",
      "+---------------------+--------------------+\n",
      "|                 450 |                  6 |\n",
      "+---------------------+--------------------+\n",
      "|                 449 |                  3 |\n",
      "+---------------------+--------------------+\n",
      "|                 448 |                  2 |\n",
      "+---------------------+--------------------+\n",
      "|                 444 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "|                 443 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "|                 442 |                  2 |\n",
      "+---------------------+--------------------+\n",
      "|                 440 |                  2 |\n",
      "+---------------------+--------------------+\n",
      "|                 439 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "|                 409 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "|                 408 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "|                 389 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "|                 380 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "|                 334 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "|                 286 |                  9 |\n",
      "+---------------------+--------------------+\n",
      "|                 285 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "|                 108 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "|                  62 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "|                  61 |                 14 |\n",
      "+---------------------+--------------------+\n",
      "|                  60 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "|                  59 |                  2 |\n",
      "+---------------------+--------------------+\n",
      "|                  57 |                  1 |\n",
      "+---------------------+--------------------+\n",
      "\n",
      "Cantidad de registros en un día completo: 451\n",
      "Días con menos de 451 registros: 53 de 1254 (4.23%)\n"
     ]
    }
   ],
   "source": [
    "resumen = analizar_registros_por_dia(df_mnq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef1314",
   "metadata": {},
   "source": [
    "Como podemos observar en la tabla, la gran mayoría de días tienen 451 muestras. Y representan más del 95% del total de los datos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee7dba",
   "metadata": {},
   "source": [
    "### 5.1. Filtrado de días incompletos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60a994",
   "metadata": {},
   "source": [
    "La siguiente función encuentra los indices de las fechas con registros incompletos (menor a 451): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "58057ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busqueda_fechas_incompletas(df: pd.DataFrame, gap_minutes: int = 1, registros_esperados: int = registros_dia_completo) -> list:\n",
    "    \"\"\"\n",
    "    Muestra una tabla con los días que tienen menos de los registros esperados o presentan irregularidades temporales.\n",
    "    Retorna una lista con esas fechas.\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame con índice datetime.\n",
    "    - gap_minutes: intervalo esperado entre registros consecutivos (en minutos).\n",
    "    - registros_esperados: cantidad esperada de registros por día.\n",
    "    \n",
    "    Retorna:\n",
    "    - Lista de fechas (datetime.date) con menos registros de los esperados o problemas temporales.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['time_diff'] = df.index.to_series().diff()\n",
    "    base_time_diff = pd.Timedelta(minutes=gap_minutes)\n",
    "\n",
    "    conteos = df.groupby(df.index.date).size()\n",
    "    fechas_problema = []\n",
    "\n",
    "    for date, group in df.groupby(df.index.date):\n",
    "        time_diff = group['time_diff'].iloc[1:]\n",
    "        tiene_irregularidades = (time_diff != base_time_diff).any()\n",
    "        cantidad = conteos[date]\n",
    "\n",
    "        if cantidad < registros_esperados or tiene_irregularidades:\n",
    "            fechas_problema.append((date, cantidad))\n",
    "\n",
    "    '''\n",
    "    if fechas_problema:\n",
    "        print(f\"\\nDía con menos de {registros_esperados} registros o con problemas temporales:\\n\")\n",
    "        print(f\"{'+' + '-'*21 + '+' + '-'*20 + '+'}\")\n",
    "        print(f\"| {'Fecha'.ljust(19)} | {'Registros'.rjust(18)} |\")\n",
    "        print(f\"{'+' + '='*21 + '+' + '='*20 + '+'}\")\n",
    "        for fecha, registros in fechas_problema:\n",
    "            print(f\"| {str(fecha).ljust(19)} | {str(registros).rjust(18)} |\")\n",
    "            print(f\"{'+' + '-'*21 + '+' + '-'*20 + '+'}\")\n",
    "    else:\n",
    "        print(\"No se encontraron días con irregularidades ni registros incompletos.\")\n",
    "    '''\n",
    "    # Solo devolver las fechas\n",
    "    return [fecha for fecha, _ in fechas_problema]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f354689",
   "metadata": {},
   "source": [
    "Elimino las fechas con registros incompletos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "53934801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de cantidad de registros por día:\n",
      "\n",
      "+---------------------+--------------------+\n",
      "|   Registros por día |   Cantidad de días |\n",
      "+=====================+====================+\n",
      "|                 451 |               1201 |\n",
      "+---------------------+--------------------+\n",
      "\n",
      "Cantidad de registros en un día completo: 451\n",
      "Días con menos de 451 registros: 0 de 1201 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Filtrar eliminando las fechas con problemas\n",
    "df_mnq = df_mnq[~df_mnq.index.to_series().dt.date.isin(busqueda_fechas_incompletas(df_mnq))]\n",
    "\n",
    "#Y verifico con:\n",
    "resumen=analizar_registros_por_dia(df_mnq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5be8e7",
   "metadata": {},
   "source": [
    "## 6. Verificación de continuidad temporal minuto a minuto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e80f60",
   "metadata": {},
   "source": [
    "Es necesario verificar que los 451 registros correspondientes a un mismo día estén dispuestos de forma consecutiva, con una separación exacta de un minuto entre cada muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2c5a40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_gaps(df: pd.DataFrame, gap_minutes: int = 1):\n",
    "    \"\"\"\n",
    "    Verifica si existen saltos mayores al intervalo esperado (por defecto 1 minuto)\n",
    "    entre registros consecutivos dentro de cada día, en un DataFrame con índice tipo DatetimeIndex.\n",
    "\n",
    "    Omite el primer registro de cada día.\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame con índice datetime.\n",
    "    - gap_minutes: tamaño esperado del intervalo en minutos (por defecto 1).\n",
    "\n",
    "    Retorna:\n",
    "    - Lista de índices donde se detectaron diferencias mayores al intervalo esperado.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['time_diff'] = df.index.to_series().diff()\n",
    "\n",
    "    base_time_diff = pd.Timedelta(minutes=gap_minutes)\n",
    "    problem_indices = []\n",
    "\n",
    "    for date, group in df.groupby(df.index.date):\n",
    "        time_diff = group['time_diff'].iloc[1:]\n",
    "        incorrect_indices = time_diff[time_diff != base_time_diff].index\n",
    "        if len(incorrect_indices) > 0:\n",
    "            problem_indices.append(incorrect_indices)\n",
    "\n",
    "    if problem_indices:\n",
    "        print(f\"Se encontraron problemas en {len(problem_indices)} registros con diferencias irregulares.\\n\")\n",
    "\n",
    "        # Conteo por fecha\n",
    "        conteos = df.groupby(df.index.date).size()\n",
    "\n",
    "        for i in range(len(problem_indices)):\n",
    "            idx = problem_indices[i][0]\n",
    "            diff = df.loc[idx, 'time_diff']\n",
    "            date = idx.date()\n",
    "            count = conteos[date]\n",
    "            print(f'\\t{idx} -> Diferencia: {diff} | # Registros: {count}')\n",
    "    else:\n",
    "        print(\"No se encontraron problemas, todas las muestras son consecutivas minuto a minuto.\")\n",
    "\n",
    "    return problem_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9136b7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontraron problemas, todas las muestras son consecutivas minuto a minuto.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectar_gaps(df_mnq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "95bf2523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 541651 entries, 2019-12-23 08:30:00-05:00 to 2024-12-27 16:00:00-05:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   open    541651 non-null  float64\n",
      " 1   high    541651 non-null  float64\n",
      " 2   low     541651 non-null  float64\n",
      " 3   close   541651 non-null  float64\n",
      " 4   volume  541651 non-null  int32  \n",
      "dtypes: float64(4), int32(1)\n",
      "memory usage: 22.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_mnq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be37b70",
   "metadata": {},
   "source": [
    "## 7. Guardado de dataset final\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6901eb",
   "metadata": {},
   "source": [
    "Se guarda un dataset compuesto por 1251 días, cada uno con 451 registros correspondientes a minutos consecutivos.\n",
    "\n",
    "El conjunto de datos incluye únicamente días hábiles de operación bursátil, y abarca el intervalo horario comprendido entre las 08:30 y las 16:00 horas (US/Eastern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7536c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data():\n",
    "    \n",
    "    archivo = 'mnq_intraday_data.parquet'\n",
    "\n",
    "    if os.path.exists(archivo):\n",
    "        print(\"Archivo existente...\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Guardando Dataset...\")\n",
    "        df_mnq.to_parquet(archivo, index=True)\n",
    "        print(f\"Dataset {archivo} guardado...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "050d6451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando Dataset...\n",
      "Dataset mnq_intraday_data.parquet guardado...\n"
     ]
    }
   ],
   "source": [
    "save_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trader_IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
