{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GUNAPILLCO/CEIA-GdP/blob/main/3_Desarrollo/2_obtencion_preparacion_exploracion_datos/2_2_limpieza_normalizaci%C3%B3n_estructuraci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fa4bfae",
      "metadata": {
        "id": "8fa4bfae"
      },
      "source": [
        "# 2_1_Limpieza, Normalizaci√≥n y estructuraci√≥n de series temporales\n",
        "# Preprocesamiento de Datos del √çndice E-mini Nasdaq 100 (MNQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5888009",
      "metadata": {
        "id": "e5888009"
      },
      "source": [
        "## 1. Importaci√≥n de Librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -q pandas_market_calendars\n",
        "print(\"‚úÖ Librer√≠a instalada: pandas_market_calendars\")"
      ],
      "metadata": {
        "id": "RuOOQhe-ntbE",
        "outputId": "980548ff-049b-40c4-9091-cdf09a877aad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RuOOQhe-ntbE",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Librer√≠a instalada: pandas_market_calendars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "614e74ca",
      "metadata": {
        "id": "614e74ca"
      },
      "outputs": [],
      "source": [
        "# Utilidades generales\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import glob\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Manejo y procesamiento de datos\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Calendario de mercados\n",
        "import pandas_market_calendars as mcal\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "265ae912",
      "metadata": {
        "id": "265ae912"
      },
      "source": [
        "## 2. Contexto y fuente de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abf4589d",
      "metadata": {
        "id": "abf4589d"
      },
      "source": [
        "Los datos corresponden al contrato MNQ (Micro E-mini Nasdaq 100) descargados desde NinjaTrader con frecuencia de un minuto (formato OHLCV).\n",
        "\n",
        "- Open: precio de apertura\n",
        "- High: precio m√°ximo\n",
        "- Low: precio m√≠nimo\n",
        "- Close: precio de cierre\n",
        "- Volume: volumen negociado\n",
        "\n",
        "Los datos est√°n en la zona horaria UTC.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ab5ec9",
      "metadata": {
        "id": "95ab5ec9"
      },
      "source": [
        "## 3. Generaci√≥n de dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8122f5c",
      "metadata": {
        "id": "c8122f5c"
      },
      "source": [
        "Dado que los contratos se encuentran almacenados en archivos .txt dentro de la carpeta historicos_mnq, es necesario unificarlos en un √∫nico dataset consolidado.\n",
        "\n",
        "La siguiente funci√≥n se encarga de leer los archivos .txt, asignar nombres a las columnas correspondientes y establecer la columna datetime como √≠ndice temporal del dataframe."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_df_desde_github():\n",
        "    base_raw = \"https://raw.githubusercontent.com/GUNAPILLCO/CEIA-GdP/main/3_Desarrollo/historicos_mnq/\"\n",
        "    fechas = [\n",
        "        \"03_20\", \"06_20\", \"09_20\", \"12_20\", \"03_21\", \"06_21\", \"09_21\", \"12_21\",\n",
        "        \"03_22\", \"06_22\", \"09_22\", \"12_22\", \"03_23\", \"06_23\", \"09_23\", \"12_23\",\n",
        "        \"03_24\", \"06_24\", \"09_24\", \"12_24\", \"03_25\"\n",
        "    ]\n",
        "\n",
        "    df_mnq = []\n",
        "\n",
        "    for i, fecha in enumerate(fechas):\n",
        "        filename = f\"{i}_mnq_{fecha}.Last.txt\"\n",
        "        url = base_raw + filename\n",
        "        print(f\"üì• Descargando {filename}...\")\n",
        "\n",
        "        response = requests.get(url)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"‚ùå Error {response.status_code} al descargar {filename}\")\n",
        "            continue\n",
        "\n",
        "        df = pd.read_csv(\n",
        "            StringIO(response.text),\n",
        "            sep=';',\n",
        "            header=None,\n",
        "            names=['datetime', 'open', 'high', 'low', 'close', 'volume'],\n",
        "            dtype={'open': float, 'high': float, 'low': float, 'close': float, 'volume': int}\n",
        "        )\n",
        "\n",
        "        df['datetime'] = pd.to_datetime(df['datetime'], format='%Y%m%d %H%M%S')\n",
        "        df.set_index('datetime', inplace=True)\n",
        "        df_mnq.append(df)\n",
        "\n",
        "    if not df_mnq:\n",
        "        raise ValueError(\"No se pudo cargar ning√∫n archivo.\")\n",
        "\n",
        "    df_mnq_raw = pd.concat(df_mnq)\n",
        "    df_mnq_raw.sort_index(inplace=True)\n",
        "    return df_mnq_raw"
      ],
      "metadata": {
        "id": "TpDY4fNtmzxs"
      },
      "id": "TpDY4fNtmzxs",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e82ebcdd",
      "metadata": {
        "id": "e82ebcdd"
      },
      "source": [
        "El siguiente bloque de c√≥digo verifica si el dataset consolidado ya ha sido generado previamente.\n",
        "\n",
        "En particular, comprueba la existencia del archivo mnq_raw_data.parquet.\n",
        "\n",
        "- Si el archivo est√° presente, se carga directamente en la variable df_mnq.\n",
        "\n",
        "- En caso contrario, se invoca la funci√≥n generate_dataset() para generar el dataset a partir de los archivos originales."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cargar_o_generar_df():\n",
        "    archivo_local = 'mnq_raw_data.parquet'\n",
        "    archivo_github_url = 'https://raw.githubusercontent.com/GUNAPILLCO/CEIA-GdP/main/3_Desarrollo/mnq_raw_data.parquet'\n",
        "\n",
        "    # 1. Verificar si el archivo existe en disco\n",
        "    if os.path.exists(archivo_local):\n",
        "        print(\"üìÇ Archivo encontrado en disco. Cargando dataset local...\")\n",
        "        df_mnq_raw = pd.read_parquet(archivo_local)\n",
        "\n",
        "    else:\n",
        "        # 2. Intentar descargar desde GitHub\n",
        "        print(\"üîç Buscando archivo en GitHub...\")\n",
        "        response = requests.get(archivo_github_url)\n",
        "        if response.status_code == 200:\n",
        "            print(\"üì• Archivo encontrado en GitHub. Descargando...\")\n",
        "            with open(archivo_local, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            df_mnq_raw = pd.read_parquet(archivo_local)\n",
        "        else:\n",
        "            # 3. Si no est√° en GitHub, generar desde .txt\n",
        "            print(\"‚ö†Ô∏è Archivo no encontrado en GitHub. Generando dataset desde archivos hist√≥ricos...\")\n",
        "            df_mnq_raw = generar_df_desde_github()\n",
        "            df_mnq_raw.to_parquet(archivo_local, index=True)\n",
        "            print(\"‚úÖ Dataset generado y guardado localmente.\")\n",
        "\n",
        "    return df_mnq_raw"
      ],
      "metadata": {
        "id": "8Xb1a8LRpsYI"
      },
      "id": "8Xb1a8LRpsYI",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "c96c833f",
      "metadata": {
        "id": "c96c833f",
        "outputId": "a1ca928e-ca4b-4da2-f716-b8fdb20e1a2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Buscando archivo en GitHub...\n",
            "üì• Archivo encontrado en GitHub. Descargando...\n"
          ]
        }
      ],
      "source": [
        "df_mnq_raw = cargar_o_generar_df()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "504382cf",
      "metadata": {
        "id": "504382cf"
      },
      "source": [
        "## 4. Filtrado de d√≠as no h√°biles y horario burs√°til"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f23cdad4",
      "metadata": {
        "id": "f23cdad4"
      },
      "source": [
        "### 4.1. Filtrado de fines de semana y feriados burs√°tiles estadounidenses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43d44470",
      "metadata": {
        "id": "43d44470"
      },
      "source": [
        "Es necesario filtrar del conjunto de datos aquellas filas correspondientes a s√°bados, domingos y feriados burs√°tiles. Para ello, se utilizar√° la librer√≠a pandas_market_calendars, que permite identificar los d√≠as h√°biles de operaci√≥n seg√∫n el calendario oficial del NASDAQ.\n",
        "\n",
        "La funci√≥n implementada filtra un DataFrame con √≠ndice de tipo DatetimeIndex, conservando √∫nicamente aquellas filas cuya fecha coincida con un d√≠a h√°bil del mercado. La marca temporal completa (fecha y hora) se mantiene sin modificaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "a7aa8f82",
      "metadata": {
        "id": "a7aa8f82"
      },
      "outputs": [],
      "source": [
        "def filtrar_dias_habiles_nasdaq(df):\n",
        "    # Crear el calendario del mercado NASDAQ\n",
        "    nasdaq = mcal.get_calendar('NASDAQ')\n",
        "\n",
        "    # Obtener el rango de fechas del √≠ndice del DataFrame\n",
        "    start_date = df.index.min().date()\n",
        "    end_date = df.index.max().date()\n",
        "\n",
        "    # Obtener el cronograma de d√≠as h√°biles del mercado\n",
        "    valid_dates = nasdaq.schedule(start_date=start_date, end_date=end_date).index.date\n",
        "\n",
        "    # Filtrar el DataFrame verificando si la fecha de cada marca temporal est√° en los d√≠as v√°lidos\n",
        "    df_filtrado = df[df.index.normalize().isin(valid_dates)]\n",
        "\n",
        "    return df_filtrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "9b91f804",
      "metadata": {
        "id": "9b91f804"
      },
      "outputs": [],
      "source": [
        "df_mnq = filtrar_dias_habiles_nasdaq (df_mnq_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3030c8ac",
      "metadata": {
        "id": "3030c8ac"
      },
      "source": [
        "### 4.2. Filtrado de horario de operaci√≥n de mercado de New York (09:30 a 16:00) con pre mercado, desde las 07:30"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "503a687c",
      "metadata": {
        "id": "503a687c"
      },
      "source": [
        "Dado que los timestamps del √≠ndice (DatetimeIndex) provienen de archivos .txt sin informaci√≥n de zona horaria, es necesario indicar expl√≠citamente a pandas que dichos valores est√°n en formato UTC.\n",
        "\n",
        "Una vez establecido el timezone, se procede a convertir los timestamps desde UTC a la hora local del mercado estadounidense (zona US/Eastern), correspondiente a los horarios de operaci√≥n del NASDAQ/NYSE. Esta conversi√≥n se realiza teniendo en cuenta autom√°ticamente los ajustes por horario de verano o invierno."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "73820485",
      "metadata": {
        "id": "73820485"
      },
      "outputs": [],
      "source": [
        "def configurar_zona_horaria(df, from_tz='UTC', to_tz='America/New_York'):\n",
        "    \"\"\"\n",
        "    Asegura que el √≠ndice del DataFrame tenga zona horaria 'from_tz'\n",
        "    y lo convierte a la zona horaria 'to_tz'.\n",
        "    \"\"\"\n",
        "    if df.index.tz is None:\n",
        "        # Localiza en from_tz si no tiene zona horaria\n",
        "        df.index = df.index.tz_localize(from_tz)\n",
        "    # Convierte a la zona horaria deseada\n",
        "    df.index = df.index.tz_convert(to_tz)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "3598a884",
      "metadata": {
        "id": "3598a884"
      },
      "outputs": [],
      "source": [
        "df_mnq = configurar_zona_horaria(df_mnq)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fb43243",
      "metadata": {
        "id": "6fb43243"
      },
      "source": [
        "La siguiente funci√≥n selecciona √∫nicamente las muestras que se encuentran dentro del horario regular de operaci√≥n burs√°til del NASDAQ.\n",
        "\n",
        "Filtra un DataFrame cuyo √≠ndice es de tipo DatetimeIndex, conservando solo aquellas filas cuya marca temporal se encuentre entre las 09:30 y 16:00 horas (US/Eastern), correspondientes al horario de negociaci√≥n est√°ndar en d√≠as h√°biles de mercado.\n",
        "\n",
        "Particularmente, decido agregar una hora de pre mercado, desde las 08:30AM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "a07ebb0e",
      "metadata": {
        "id": "a07ebb0e"
      },
      "outputs": [],
      "source": [
        "def filtrar_horas_habiles_nasdaq(df):\n",
        "\n",
        "    # Filtrar solo las filas dentro de las horas de mercado (de 8:30 AM a 4:00 PM)\n",
        "    df_filtered = df.between_time('07:30:00', '16:00:00')\n",
        "\n",
        "    # Retornar el DataFrame filtrado\n",
        "    return df_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "1514117c",
      "metadata": {
        "id": "1514117c"
      },
      "outputs": [],
      "source": [
        "df_mnq = filtrar_horas_habiles_nasdaq(df_mnq)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb71ac27",
      "metadata": {
        "id": "bb71ac27"
      },
      "source": [
        "## 5. An√°lisis de registros diarios"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eed73d4",
      "metadata": {
        "id": "4eed73d4"
      },
      "source": [
        "Es necesario verificar que todos los d√≠as del conjunto de datos contengan la misma cantidad de registros y que estos sean consecutivos, es decir, que no falte ning√∫n minuto dentro de cada jornada.\n",
        "\n",
        "La funci√≥n analizar_registros_por_dia permite realizar este control sobre un DataFrame con √≠ndice de tipo datetime. La funci√≥n contabiliza la cantidad de registros por d√≠a e imprime una tabla resumen que indica cu√°ntos d√≠as presentan una determinada cantidad de registros. Esto resulta √∫til para identificar inconsistencias, como d√≠as incompletos o interrupciones en la frecuencia temporal esperada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "6b03a076",
      "metadata": {
        "id": "6b03a076"
      },
      "outputs": [],
      "source": [
        "def analizar_registros_por_dia(df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Analiza la cantidad de registros por d√≠a en un DataFrame con √≠ndice datetime.\n",
        "\n",
        "    Imprime:\n",
        "    - Distribuci√≥n de la cantidad de registros por d√≠a.\n",
        "    - Porcentaje de d√≠as con menos registros que el valor m√°s frecuente.\n",
        "\n",
        "    Retorna:\n",
        "    - Serie con el conteo de registros por cada d√≠a.\n",
        "    \"\"\"\n",
        "    # Contar la cantidad de registros por d√≠a\n",
        "    conteo_diario = df.groupby(df.index.date).size()\n",
        "\n",
        "    # Calcular la distribuci√≥n de registros por d√≠a\n",
        "    distribucion = conteo_diario.value_counts().sort_index(ascending=False)\n",
        "    tabla = [[registros, cantidad_dias] for registros, cantidad_dias in distribucion.items()]\n",
        "\n",
        "    print(\"Distribuci√≥n de cantidad de registros por d√≠a:\\n\")\n",
        "    print(tabulate(tabla, headers=[\"Registros por d√≠a\", \"Cantidad de d√≠as\"], tablefmt=\"grid\"))\n",
        "\n",
        "    # Determinar el valor m√°s frecuente de registros por d√≠a\n",
        "    registros_dia_completo = conteo_diario.mode().iloc[0]\n",
        "    print(f\"\\nCantidad de registros en un d√≠a completo: {registros_dia_completo}\")\n",
        "\n",
        "    # Calcular el porcentaje de d√≠as incompletos\n",
        "    total_dias = len(conteo_diario)\n",
        "    dias_con_menos = (conteo_diario < registros_dia_completo).sum()\n",
        "    porcentaje = (dias_con_menos / total_dias) * 100\n",
        "\n",
        "    print(f\"D√≠as con menos de {registros_dia_completo} registros: {dias_con_menos} de {total_dias} ({porcentaje:.2f}%)\")\n",
        "\n",
        "    return conteo_diario, registros_dia_completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "15b8e1dd",
      "metadata": {
        "id": "15b8e1dd",
        "outputId": "bc57b059-65b6-4bf4-a018-588673654a5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribuci√≥n de cantidad de registros por d√≠a:\n",
            "\n",
            "+---------------------+--------------------+\n",
            "|   Registros por d√≠a |   Cantidad de d√≠as |\n",
            "+=====================+====================+\n",
            "|                 511 |               1198 |\n",
            "+---------------------+--------------------+\n",
            "|                 510 |                  8 |\n",
            "+---------------------+--------------------+\n",
            "|                 509 |                  4 |\n",
            "+---------------------+--------------------+\n",
            "|                 508 |                  2 |\n",
            "+---------------------+--------------------+\n",
            "|                 504 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 503 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 502 |                  2 |\n",
            "+---------------------+--------------------+\n",
            "|                 500 |                  2 |\n",
            "+---------------------+--------------------+\n",
            "|                 499 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 458 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 432 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 404 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 394 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 383 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 346 |                  9 |\n",
            "+---------------------+--------------------+\n",
            "|                 344 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 122 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 121 |                  9 |\n",
            "+---------------------+--------------------+\n",
            "|                 120 |                  3 |\n",
            "+---------------------+--------------------+\n",
            "|                 119 |                  2 |\n",
            "+---------------------+--------------------+\n",
            "|                 118 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 117 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 116 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 109 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "|                 108 |                  1 |\n",
            "+---------------------+--------------------+\n",
            "\n",
            "Cantidad de registros en un d√≠a completo: 511\n",
            "D√≠as con menos de 511 registros: 56 de 1254 (4.47%)\n"
          ]
        }
      ],
      "source": [
        "resumen, registros_dia_completo = analizar_registros_por_dia(df_mnq)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cef1314",
      "metadata": {
        "id": "5cef1314"
      },
      "source": [
        "Como podemos observar en la tabla, la gran mayor√≠a de d√≠as tienen `511` muestras. Y representan m√°s del 95% del total de los datos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aee7dba",
      "metadata": {
        "id": "3aee7dba"
      },
      "source": [
        "### 5.1. Filtrado de d√≠as incompletos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc60a994",
      "metadata": {
        "id": "fc60a994"
      },
      "source": [
        "La siguiente funci√≥n encuentra los indices de las fechas con registros incompletos (menor a 511):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "58057ccf",
      "metadata": {
        "id": "58057ccf"
      },
      "outputs": [],
      "source": [
        "def busqueda_fechas_incompletas(df: pd.DataFrame, gap_minutes: int = 1, registros_esperados: int = registros_dia_completo) -> list:\n",
        "    \"\"\"\n",
        "    Muestra una tabla con los d√≠as que tienen menos de los registros esperados o presentan irregularidades temporales.\n",
        "    Retorna una lista con esas fechas.\n",
        "\n",
        "    Par√°metros:\n",
        "    - df: DataFrame con √≠ndice datetime.\n",
        "    - gap_minutes: intervalo esperado entre registros consecutivos (en minutos).\n",
        "    - registros_esperados: cantidad esperada de registros por d√≠a.\n",
        "\n",
        "    Retorna:\n",
        "    - Lista de fechas (datetime.date) con menos registros de los esperados o problemas temporales.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df['time_diff'] = df.index.to_series().diff()\n",
        "    base_time_diff = pd.Timedelta(minutes=gap_minutes)\n",
        "\n",
        "    conteos = df.groupby(df.index.date).size()\n",
        "    fechas_problema = []\n",
        "\n",
        "    for date, group in df.groupby(df.index.date):\n",
        "        time_diff = group['time_diff'].iloc[1:]\n",
        "        tiene_irregularidades = (time_diff != base_time_diff).any()\n",
        "        cantidad = conteos[date]\n",
        "\n",
        "        if cantidad < registros_esperados or tiene_irregularidades:\n",
        "            fechas_problema.append((date, cantidad))\n",
        "\n",
        "    '''\n",
        "    if fechas_problema:\n",
        "        print(f\"\\nD√≠a con menos de {registros_esperados} registros o con problemas temporales:\\n\")\n",
        "        print(f\"{'+' + '-'*21 + '+' + '-'*20 + '+'}\")\n",
        "        print(f\"| {'Fecha'.ljust(19)} | {'Registros'.rjust(18)} |\")\n",
        "        print(f\"{'+' + '='*21 + '+' + '='*20 + '+'}\")\n",
        "        for fecha, registros in fechas_problema:\n",
        "            print(f\"| {str(fecha).ljust(19)} | {str(registros).rjust(18)} |\")\n",
        "            print(f\"{'+' + '-'*21 + '+' + '-'*20 + '+'}\")\n",
        "    else:\n",
        "        print(\"No se encontraron d√≠as con irregularidades ni registros incompletos.\")\n",
        "    '''\n",
        "    # Solo devolver las fechas\n",
        "    return [fecha for fecha, _ in fechas_problema]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f354689",
      "metadata": {
        "id": "3f354689"
      },
      "source": [
        "Elimino las fechas con registros incompletos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "53934801",
      "metadata": {
        "id": "53934801",
        "outputId": "d2b0544d-1c35-42c6-d8bf-ed0daec1d335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribuci√≥n de cantidad de registros por d√≠a:\n",
            "\n",
            "+---------------------+--------------------+\n",
            "|   Registros por d√≠a |   Cantidad de d√≠as |\n",
            "+=====================+====================+\n",
            "|                 511 |               1198 |\n",
            "+---------------------+--------------------+\n",
            "\n",
            "Cantidad de registros en un d√≠a completo: 511\n",
            "D√≠as con menos de 511 registros: 0 de 1198 (0.00%)\n"
          ]
        }
      ],
      "source": [
        "# Filtrar eliminando las fechas con problemas\n",
        "df_mnq = df_mnq[~df_mnq.index.to_series().dt.date.isin(busqueda_fechas_incompletas(df_mnq))]\n",
        "\n",
        "#Y verifico con:\n",
        "resumen=analizar_registros_por_dia(df_mnq)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e5be8e7",
      "metadata": {
        "id": "2e5be8e7"
      },
      "source": [
        "## 6. Verificaci√≥n de continuidad temporal minuto a minuto"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e80f60",
      "metadata": {
        "id": "23e80f60"
      },
      "source": [
        "Es necesario verificar que los 451 registros correspondientes a un mismo d√≠a est√©n dispuestos de forma consecutiva, con una separaci√≥n exacta de un minuto entre cada muestra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "2c5a40c1",
      "metadata": {
        "id": "2c5a40c1"
      },
      "outputs": [],
      "source": [
        "def detectar_gaps(df: pd.DataFrame, gap_minutes: int = 1):\n",
        "    \"\"\"\n",
        "    Verifica si existen saltos mayores al intervalo esperado (por defecto 1 minuto)\n",
        "    entre registros consecutivos dentro de cada d√≠a, en un DataFrame con √≠ndice tipo DatetimeIndex.\n",
        "\n",
        "    Omite el primer registro de cada d√≠a.\n",
        "\n",
        "    Par√°metros:\n",
        "    - df: DataFrame con √≠ndice datetime.\n",
        "    - gap_minutes: tama√±o esperado del intervalo en minutos (por defecto 1).\n",
        "\n",
        "    Retorna:\n",
        "    - Lista de √≠ndices donde se detectaron diferencias mayores al intervalo esperado.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df['time_diff'] = df.index.to_series().diff()\n",
        "\n",
        "    base_time_diff = pd.Timedelta(minutes=gap_minutes)\n",
        "    problem_indices = []\n",
        "\n",
        "    for date, group in df.groupby(df.index.date):\n",
        "        time_diff = group['time_diff'].iloc[1:]\n",
        "        incorrect_indices = time_diff[time_diff != base_time_diff].index\n",
        "        if len(incorrect_indices) > 0:\n",
        "            problem_indices.append(incorrect_indices)\n",
        "\n",
        "    if problem_indices:\n",
        "        print(f\"Se encontraron problemas en {len(problem_indices)} registros con diferencias irregulares.\\n\")\n",
        "\n",
        "        # Conteo por fecha\n",
        "        conteos = df.groupby(df.index.date).size()\n",
        "\n",
        "        for i in range(len(problem_indices)):\n",
        "            idx = problem_indices[i][0]\n",
        "            diff = df.loc[idx, 'time_diff']\n",
        "            date = idx.date()\n",
        "            count = conteos[date]\n",
        "            print(f'\\t{idx} -> Diferencia: {diff} | # Registros: {count}')\n",
        "    else:\n",
        "        print(\"No se encontraron problemas, todas las muestras son consecutivas minuto a minuto.\")\n",
        "\n",
        "    return problem_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "9136b7ba",
      "metadata": {
        "id": "9136b7ba",
        "outputId": "bc2d509f-8d7a-456a-b4b7-3c8bb0706ea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No se encontraron problemas, todas las muestras son consecutivas minuto a minuto.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "detectar_gaps(df_mnq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "95bf2523",
      "metadata": {
        "id": "95bf2523",
        "outputId": "427c4d94-65c0-41cf-c7ed-9d3306aaeb1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 612178 entries, 2019-12-23 07:30:00-05:00 to 2024-12-27 16:00:00-05:00\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   open    612178 non-null  float64\n",
            " 1   high    612178 non-null  float64\n",
            " 2   low     612178 non-null  float64\n",
            " 3   close   612178 non-null  float64\n",
            " 4   volume  612178 non-null  int32  \n",
            "dtypes: float64(4), int32(1)\n",
            "memory usage: 25.7 MB\n"
          ]
        }
      ],
      "source": [
        "df_mnq.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be37b70",
      "metadata": {
        "id": "9be37b70"
      },
      "source": [
        "## 7. Guardado de dataset final\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b6901eb",
      "metadata": {
        "id": "0b6901eb"
      },
      "source": [
        "Se guarda un dataset compuesto por 1251 d√≠as, cada uno con 451 registros correspondientes a minutos consecutivos.\n",
        "\n",
        "El conjunto de datos incluye √∫nicamente d√≠as h√°biles de operaci√≥n burs√°til, y abarca el intervalo horario comprendido entre las 08:30 y las 16:00 horas (US/Eastern)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "7536c136",
      "metadata": {
        "id": "7536c136"
      },
      "outputs": [],
      "source": [
        "def save_data():\n",
        "\n",
        "    archivo = 'mnq_intraday_data.parquet'\n",
        "\n",
        "    if os.path.exists(archivo):\n",
        "        print(\"Archivo existente...\")\n",
        "\n",
        "    else:\n",
        "        print(\"Guardando Dataset...\")\n",
        "        df_mnq.to_parquet(archivo, index=True)\n",
        "        print(f\"Dataset {archivo} guardado...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "050d6451",
      "metadata": {
        "id": "050d6451",
        "outputId": "af9e8660-e3f0-40c5-b68b-871cb3cc2c6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guardando Dataset...\n",
            "Dataset mnq_intraday_data.parquet guardado...\n"
          ]
        }
      ],
      "source": [
        "save_data()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "trader_IA",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}